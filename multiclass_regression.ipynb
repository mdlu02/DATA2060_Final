{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA 2060 Final Notebook**\n",
    "\n",
    "blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as it\n",
    "import logistic_regression as lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One vs. All Logistic Regression multi-class regression classifier ###\n",
    "\n",
    "class OneVsAll:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_classes: int,\n",
    "        batch_size: int,\n",
    "        conv_threshold: float\n",
    "    ) -> None:\n",
    "        self.n_classes = n_classes\n",
    "        self.models = [\n",
    "            lr.LogisticRegression(n_features, 2, batch_size, conv_threshold) \n",
    "            for _ in range(n_classes)\n",
    "        ]\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray) -> None:\n",
    "        # Train a binary classifier for each class against all others\n",
    "        for class_label in range(self.n_classes):\n",
    "            binary_labels = (Y == class_label).astype(int)\n",
    "            self.models[class_label].train(X, binary_labels)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Get the probabilities of each class for each data point\n",
    "        probabilities = np.array([\n",
    "            model.predict(X) for model in self.models\n",
    "        ])\n",
    "\n",
    "        # Return the class with the highest probability for each data point\n",
    "        return np.argmax(probabilities, axis=0)\n",
    "\n",
    "    def accuracy(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All Pairs Logistic Regression multi-class regression classifier ###\n",
    "\n",
    "class AllPairs:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_classes: int,\n",
    "        batch_size: int,\n",
    "        conv_threshold: float,\n",
    "    ):\n",
    "        self.n_classes = n_classes\n",
    "        self.pairs = list(it.combinations(range(n_classes), 2))\n",
    "        self.models = {\n",
    "            (i, j): lr.LogisticRegression(\n",
    "                n_features,\n",
    "                2,\n",
    "                batch_size,\n",
    "                conv_threshold\n",
    "            )\n",
    "            for i, j in self.pairs\n",
    "        }\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray) -> None:\n",
    "        # Iterate over all pair combinations\n",
    "        for i, j in self.pairs:\n",
    "            indices = (Y == i) | (Y == j)\n",
    "\n",
    "            # Get appropriate data\n",
    "            X_pair, Y_pair = X[indices], Y[indices]\n",
    "            Y_pair = (Y_pair == i).astype(int)\n",
    "\n",
    "            # Train on the pair\n",
    "            self.models[(i, j)].train(X_pair, Y_pair)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Count predictions for each class\n",
    "        votes = np.zeros((len(X), self.n_classes))\n",
    "        for (i, j), model in self.models.items():\n",
    "            predictions = model.predict(X)\n",
    "            votes[:, i] += predictions\n",
    "            votes[:, j] += 1 - predictions\n",
    "\n",
    "        # Return the class with the most predictions\n",
    "        return np.argmax(votes, axis=1)\n",
    "\n",
    "    def accuracy(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-All Accuracy: 0.192\n",
      "All-Pairs Accuracy: 0.282\n"
     ]
    }
   ],
   "source": [
    "### Dummy test ###\n",
    "\n",
    "n_samples = 500\n",
    "n_features = 10\n",
    "n_classes = 5\n",
    "X = np.random.rand(n_samples, n_features + 1)\n",
    "Y = np.random.randint(0, n_classes, n_samples)\n",
    "\n",
    "# One-vs-All\n",
    "ova = OneVsAll(n_features, n_classes, batch_size=32, conv_threshold=1e-4)\n",
    "ova.train(X, Y)\n",
    "print(f\"One-vs-All Accuracy: {ova.accuracy(X, Y)}\")\n",
    "\n",
    "# All-Pairs\n",
    "all_pairs = AllPairs(n_features, n_classes, batch_size=32, conv_threshold=1e-4)\n",
    "all_pairs.train(X, Y)\n",
    "print(f\"All-Pairs Accuracy: {all_pairs.accuracy(X, Y)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
