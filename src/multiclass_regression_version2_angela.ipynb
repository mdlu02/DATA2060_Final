{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA 2060 Final Notebook**\n",
    "\n",
    "blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    '''\n",
    "    Apply softmax to an array\n",
    "    @params:\n",
    "        x: the original array\n",
    "    @return:\n",
    "        an array with softmax applied elementwise.\n",
    "    '''\n",
    "    inner = np.array(x - np.max(x))\n",
    "    e = np.exp(inner.astype(np.float64))\n",
    "    return (e + 1e-6) / (np.sum(e) + 1e-6)\n",
    "\n",
    "class LogisticRegression:\n",
    "    '''\n",
    "    Multiclass Logistic Regression that learns weights using \n",
    "    stochastic gradient descent.\n",
    "    '''\n",
    "    def __init__(self, n_features, n_classes, batch_size, conv_threshold):\n",
    "        '''\n",
    "        Initializes a LogisticRegression classifer.\n",
    "        @attrs:\n",
    "            n_features: the number of features in the classification problem\n",
    "            n_classes: the number of classes in the classification problem\n",
    "            weights: The weights of the Logistic Regression model\n",
    "            alpha: The learning rate used in stochastic gradient descent\n",
    "        '''\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = n_features\n",
    "        self.weights = np.zeros((n_classes, n_features)) \n",
    "        self.alpha = 0.03  # DO NOT TUNE THIS PARAMETER\n",
    "        self.batch_size = batch_size\n",
    "        self.conv_threshold = conv_threshold\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        '''\n",
    "        Trains the model using stochastic gradient descent\n",
    "        @params:\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "            Y: a 1D Numpy array containing the corresponding labels for each example\n",
    "        @return:\n",
    "            num_epochs: integer representing the number of epochs taken to reach convergence\n",
    "        '''\n",
    "        #had to replace train function, should pass unit tests from HW now\n",
    "        w = self.weights\n",
    "        alpha = self.alpha\n",
    "        b = self.batch_size\n",
    "        num_epoch = 0\n",
    "        converge = False\n",
    "        X_and_Y = np.hstack([X,np.zeros([1,len(Y)]).T]) #so when we shuffle the labels and examples still match up\n",
    "        X_and_Y[:,-1] = Y\n",
    "        while converge == False:\n",
    "            num_epoch += 1\n",
    "            np.random.shuffle(X_and_Y) #shuffle training data, so X_and_Y is now a shuffled matrix\n",
    "            shuffled_X = X_and_Y[:,:-1]\n",
    "            shuffled_Y = X_and_Y[:,-1]\n",
    "            last_epoch_loss = self.loss(X,Y) #calculate loss with our current weights\n",
    "            for i in range(0,int(np.ceil(len(Y)/b))):\n",
    "                X_batch = shuffled_X[i*b:(i+1)*b,:]\n",
    "                Y_batch = shuffled_Y[i*b:(i+1)*b] #1xn array\n",
    "                deriv_L_w = np.zeros(np.shape(w)) #our derivative L_w matrix\n",
    "                for data_point_row in range(0,len(Y_batch)):\n",
    "                    for j in range(0,self.n_classes):\n",
    "                        x = X_batch[data_point_row,:]\n",
    "                        if Y_batch[data_point_row] == j:\n",
    "                            deriv_L_w[j,:] = deriv_L_w[j,:]+(softmax(w@x.T)[j]-1)*x\n",
    "                        else:\n",
    "                            deriv_L_w[j,:] = deriv_L_w[j,:]+softmax(w@x.T)[j]*x\n",
    "                            \n",
    "                w = w - (alpha*deriv_L_w)/len(X_batch)\n",
    "\n",
    "            self.weights = w\n",
    "            this_epoch_loss = self.loss(X,Y) #calculate loss with our new weights\n",
    "            if np.abs(this_epoch_loss-last_epoch_loss) < self.conv_threshold:\n",
    "                converge = True\n",
    "        #print('number of epochs: ' + str(num_epoch))\n",
    "        return num_epoch\n",
    "        \n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        '''\n",
    "        Returns the total log loss on some dataset (X, Y), divided by the number of examples.\n",
    "        @params:\n",
    "            X: 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "            Y: 1D Numpy array containing the corresponding labels for each example\n",
    "        @return:\n",
    "            A float number which is the average loss of the model on the dataset\n",
    "        '''   \n",
    "        # calculate loss for each example (x,y), then average them\n",
    "            \n",
    "        h_w_x_softmax = np.zeros([self.n_classes,len(X)])\n",
    "        for i in range(0,len(X)):\n",
    "            h_w_x_softmax[:,i] = self.getSoftmaxProbability(X[i,:])\n",
    "        loss_sum = 0\n",
    "        for j in range(0,len(Y)):\n",
    "            loss_sum += -np.log(h_w_x_softmax[int(Y[j]),j])\n",
    "        return loss_sum/len(Y)\n",
    "\n",
    "        \n",
    "    def getSoftmaxProbability(self, x):\n",
    "        '''\n",
    "        Compute softmax regular probability vector of an example belonging to each possible class.\n",
    "        @params:\n",
    "            x: a 1D Numpy array that is one example from the training set, padded by 1 column for the bias\n",
    "        @return:\n",
    "            A 1D Numpy array with one element for each possible class j, \n",
    "            where the element at j represents the probability of x belonging to j.\n",
    "        '''\n",
    "        return softmax(np.dot(self.weights, x))\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Compute predictions based on the learned weigths and examples X\n",
    "        @params:\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "        @return:\n",
    "            A 1D Numpy array with one element for each row in X containing the predicted class.\n",
    "        '''\n",
    "        # use one vs all algorithm for returning class with highest probablity of that x belonging to it\n",
    "        # let j be each possible class\n",
    "\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            normalized_prob = self.getSoftmaxProbability(x)\n",
    "            # print(\"norm prob:\", normalized_prob.shape)\n",
    "            # the index of highest probablity is used as the predicted class\n",
    "            x_prediction = np.argmax(normalized_prob)\n",
    "            predictions.append(x_prediction)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def accuracy(self, X, Y):\n",
    "        '''\n",
    "        Outputs the accuracy of the trained model on a given testing dataset X and labels Y.\n",
    "        @params:\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "            Y: a 1D Numpy array containing the corresponding labels for each example\n",
    "        @return:\n",
    "            a float number indicating accuracy (between 0 and 1)\n",
    "        '''\n",
    "\n",
    "        # count how many 0s (accurately predicted examples) from the difference\n",
    "        predict = self.predict(X)\n",
    "        diff = predict - Y\n",
    "        num_correct = np.sum(diff == 0)\n",
    "\n",
    "        accuracy = num_correct/len(Y)\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.07110925e-01  7.07102633e-01  7.74907346e-05]\n",
      " [ 7.07110925e-01 -7.07102631e-01 -9.70796080e-05]]\n",
      "[[ 7.07106554e-01 -7.07107007e-01  4.91705528e-05]]\n",
      "[ 0.70896684 -0.70520629 -0.00707821]\n",
      "[ 7.08533355e-01 -7.05677214e-01  3.92440976e-04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_gsp_1 = np.array([[-0.5,5,1],[1,1,1],[10,2,1],[-10,-2,1],[2,1,1]])\n",
    "y_gsp_1 = np.array([0,1,1,0,1])\n",
    "\n",
    "X_gsp_1 = np.array([[-2,0,1],[-1,0,1],[-1,1,1],[0,2,1],[0,1,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_gsp_1 = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "log_reg = LogisticRegression(3,2,1,1e-4)\n",
    "sk_log_reg_model = sklearn_SGDClassifier(loss = 'log_loss', fit_intercept = False, penalty = None,learning_rate = 'constant',eta0=0.03,tol=1e-4,n_iter_no_change=1)\n",
    "log_reg.fit(X_gsp_1,y_gsp_1)\n",
    "sk_log_reg_model.fit(X_gsp_1,y_gsp_1)\n",
    "\n",
    "print(normalize(log_reg.weights,axis=1))\n",
    "print(normalize(sk_log_reg_model.coef_))\n",
    "\n",
    "X_2 = np.array([[-2,0,1],[-1,0,1],[-1,1,1],[0,2,1],[0,1,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_2 = np.array([0,0,1,0,0,1,1,1,0,1])\n",
    "\n",
    "log_reg.fit(X_2,y_2)\n",
    "sk_log_reg_model.fit(X_2,y_2)\n",
    "print(normalize(log_reg.weights,axis=1)[1,:])\n",
    "print(normalize(sk_log_reg_model.coef_)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all tests!\n"
     ]
    }
   ],
   "source": [
    "### Unit Tests LogisticRegression ###\n",
    "import pytest\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier as SKSGDClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#softmax function, calculated results by hand\n",
    "softmax_test_1 = np.array([1,2,3,4,5]) #generic example\n",
    "assert softmax(softmax_test_1) == pytest.approx([0.01166,0.03168,0.08612,0.23412,0.6364086], .001)\n",
    "softmax_test_2 = np.array([-2,0,3,-2,3]) #tests if can handle multiple of the same values/max value occurs multiple times\n",
    "assert softmax(softmax_test_2) == pytest.approx([0.003266,0.024131,0.484669,0.003266,0.484669], .001)\n",
    "\n",
    "\n",
    "#weights during fit\n",
    "#training points can be split by a halfspace, \n",
    "X_weights_1 = np.array([[-2,0,1],[-1,0,1],[-1,1,1],[0,2,1],[0,1,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_weights_1 = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "#the training points cannot be split by a halfspace, at least 2 training points will have to be mislabeled\n",
    "X_weights_2 = np.array([[-2,0,1],[-1,0,1],[-1,1,1],[0,2,1],[0,1,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_weights_2 = np.array([0,0,1,0,0,1,1,1,0,1])\n",
    "\n",
    "own_log_reg = LogisticRegression(3,2,1,1e-4)\n",
    "#penalty = None means no regularization, learning rate = eta0 is our alpha in LogisticRegression, tolerance = tol set to our convergence threshold, n_iter_no_change = 1 means if we hit convergence once to stop\n",
    "sk_sgd_log_reg = SKSGDClassifier(loss = 'log_loss', fit_intercept = False, penalty = None,learning_rate = 'constant',eta0=0.03,tol=1e-4,n_iter_no_change=1)\n",
    "\n",
    "#first check shape of weights\n",
    "assert (own_log_reg.weights.shape == np.array([2,3])).all()\n",
    "\n",
    "#check for each of these datasets, if the normalized weights for each model are within 0.01 of each other for each feature\n",
    "own_log_reg.fit(X_weights_1,y_weights_1)\n",
    "sk_sgd_log_reg.fit(X_weights_1,y_weights_1)\n",
    "assert (abs(normalize(own_log_reg.weights,axis=1)[1] - normalize(sk_sgd_log_reg.coef_)[0]) <= 0.01).all()\n",
    "\n",
    "own_log_reg.fit(X_weights_2,y_weights_2)\n",
    "sk_sgd_log_reg.fit(X_weights_2,y_weights_2)\n",
    "assert (abs(normalize(own_log_reg.weights,axis=1)[1] - normalize(sk_sgd_log_reg.coef_)[0]) <= 0.01).all()\n",
    "        \n",
    "\n",
    "\n",
    "#### loss function ###\n",
    "log_reg = LogisticRegression(3,2,1,1e-4)\n",
    "log_reg.weights = np.array([[-0.5,2,0.1],[0.5,-2,-0.1]]) #set weights to some random 2 class, 3 features (including bias) array\n",
    "#test on dataset with one datapoint\n",
    "#case with vector of all 0's, should be same loss for both classes\n",
    "X_loss_1 = np.array([[0,0,0]])\n",
    "assert log_reg.loss(X_loss_1,np.array([0])) == pytest.approx(np.array([0.6931472]),0.001) #-ln(0.5)\n",
    "assert log_reg.loss(X_loss_1,np.array([1])) == pytest.approx(np.array([0.6931472]),0.001)\n",
    "\n",
    "#with multiple datapoints, random test\n",
    "X_loss_2 = np.array([[-1,2,0.3],[1.5,-0.1,2]])\n",
    "y_loss_2 = np.array([0,1])\n",
    "assert log_reg.loss(X_loss_2,y_loss_2) == pytest.approx(0.10076465,0.001)\n",
    "\n",
    "\n",
    "\n",
    "### getSoftmaxProbability function ###\n",
    "X_gsp_1 = np.array([[-0.5,5,1],[1,1,1],[10,2,1],[-10,-2,1],[2,1,1]]) #random test data with bias included\n",
    "y_gsp_1 = np.array([0,1,1,0,1])\n",
    "\n",
    "log_reg = LogisticRegression(3,2,1,1e-4)\n",
    "log_reg.fit(X_gsp_1,y_gsp_1)\n",
    "test_gsp_1 = np.array([0,0,0])\n",
    "\n",
    "#no matter our weights, if datapoint is vector of 0's, getSoftmaxProbability should give us around an equal probability for each class\n",
    "assert log_reg.getSoftmaxProbability(test_gsp_1) == pytest.approx(np.array([0.5,0.5]),0.001) \n",
    "#set weights to some random 2 class, 3 features (including bias) array, test on random datapoint\n",
    "log_reg.weights = np.array([[-0.5,2,0.1],[0.5,-2,-0.1]])\n",
    "test_gsp_2 = np.array([3,-0.9,1.3])\n",
    "assert log_reg.getSoftmaxProbability(test_gsp_2) == pytest.approx(np.array([0.0017612,0.9982388]),0.001) #calculated by hand\n",
    "\n",
    "\n",
    "\n",
    "### predict function ###\n",
    "#the training points can be split by a halfspace\n",
    "X_1 = np.array([[-2,0,1],[-1,0,1],[-1,1,1],[0,2,1],[0,1,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_1 = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "X_test_1 = np.array([[0,5,1],[-10,1,1],[-2,2,1],[2,-2,1],[1,-10,1],[5,0,1]]) #includes terms that would be right on the edge of a correct halfspace\n",
    "\n",
    "#the training points cannot be split by a halfspace, at least 2 training points will have to be mislabeled\n",
    "X_2 = np.array([[-2,0,1],[-1,0,1],[-1,1,1],[0,2,1],[0,1,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_2 = np.array([0,0,1,0,0,1,1,1,0,1])\n",
    "X_test_2 = np.array([[0,5,1],[-10,1,1],[-2,2,1],[2,-2,1],[1,-10,1],[5,0,1]]) #includes terms that would be right on the edge of a correct halfspace\n",
    "\n",
    "#uneven number of training points for each label\n",
    "X_3 = np.array([[-2,0,1],[-1,1,1],[0,2,1],[0,-1,1],[0,-2,1],[1,0,1],[1,-1,1],[2,0,1]]) #includes bias term\n",
    "y_3 = np.array([0,0,0,1,1,1,1,1])\n",
    "X_test_3 = np.array([[0,5,1],[-10,1,1],[-2,2,1],[2,-2,1],[1,-10,1],[5,0,1]]) #includes terms that would be right on the edge of a correct halfspace\n",
    "\n",
    "#initialize LogisticRegression model with n_classes = 2, batch_size = 1, conv_threshold = 1e-4\n",
    "log_reg = LogisticRegression(3,2,1,1e-4)\n",
    "\n",
    "#train our LogisticRegression model on each training dataset, then test predictions\n",
    "log_reg.fit(X_1,y_1)\n",
    "assert (log_reg.predict(X_test_1) == np.array([0,0,0,1,1,1])).all()\n",
    "\n",
    "log_reg.fit(X_2,y_2)\n",
    "assert (log_reg.predict(X_test_2) == np.array([0,0,0,1,1,1])).all()\n",
    "\n",
    "log_reg.fit(X_3,y_3)\n",
    "assert (log_reg.predict(X_test_3) == np.array([0,0,0,1,1,1])).all()\n",
    "\n",
    "\n",
    "\n",
    "### accuracy function ###\n",
    "#test accuracy based on previous prediction tests, we know prediction should be [0,0,0,1,1,1]\n",
    "accuracy_test_1 = np.array([1,1,1,0,0,0]) #make sure labeling is correct (flip labels, get 0 accuracy)\n",
    "accuracy_test_2 = np.array([1,0,0,1,0,1]) #make sure percentage for accuracy is correct to the nearest 0.001 for long decimals\n",
    "log_reg.fit(X_1,y_1)\n",
    "assert log_reg.accuracy(X_test_1, accuracy_test_1) == 0\n",
    "assert log_reg.accuracy(X_test_1, accuracy_test_2) == pytest.approx(0.667,0.001)\n",
    "\n",
    "print('Passed all tests!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempted unit tests for Logistic Regression class and softmax functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "own log reg predictions:\n",
      "[1 1 0 1 0]\n",
      "sklearn log reg predictions:\n",
      "[1 1 0 1 0]\n",
      "[[ 0.93643481 -1.41140007  0.12291163]\n",
      " [-0.93646024  1.41138718 -0.12294918]]\n",
      "[[-1.63431988  2.4166285  -0.23592541]]\n",
      "[1 1 1 1 0 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[[-0.66010379  0.24330464  0.67263192  0.61904541 -0.16628908 -0.57664825]\n",
      " [ 0.66008693 -0.24332256 -0.67264786 -0.61906199  0.16627398  0.57661731]]\n",
      "[[ 0.40167959 -0.08675389 -0.29310007 -0.34243455  0.09834801  0.22974414]]\n",
      "[0 1 0 1 1]\n",
      "[0 1 1 1 0]\n",
      "[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier as sklearn_SGDClassifier\n",
    "#test for softmax, calculated results by hand\n",
    "softmax_test_1 = np.array([1,2,3,4,5]) #generic example\n",
    "assert softmax(softmax_test_1) == pytest.approx([0.01166,0.03168,0.08612,0.23412,0.6364086], .001)\n",
    "softmax_test_2 = np.array([-2,0,3,-2,3]) #tests if can handle multiple of the same values/max value occurs multiple times\n",
    "assert softmax(softmax_test_2) == pytest.approx([0.003266,0.024131,0.484669,0.003266,0.484669], .001)\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "#test for our logistic regression function with that from sklearn\n",
    "X_1 = np.array([[1,2],[2.3,6,],[-9,0],[-1,2.34]]) #generic example\n",
    "bias_1 = np.ones((len(X_1),1))\n",
    "X_1 = np.hstack((X_1, bias_1))\n",
    "Y_1 = np.array([1,1,0,0]) #binary\n",
    "\n",
    "X_test_1 = np.array([[3,4,1],[-90,1,1],[3.2,-2.2,1],[-22,4.3,1]])\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "conv_thresh = 0.01\n",
    "own_log_reg_model = LogisticRegression(len(X_1[0,:]),2,batch_size,conv_thresh) #num_features does not include bias, our own model\n",
    "own_log_reg_model.fit(X_1,Y_1)\n",
    "sklearn_log_reg_model = SKLogisticRegression(fit_intercept = False,tol=conv_thresh,C=1) #sklearn LogisticRegression model\n",
    "sklearn_log_reg_model.fit(X_1,Y_1)\n",
    "sklearn_SGD_model = sklearn_SGDClassifier(loss='log_loss',fit_intercept = False,alpha=0.03,tol=conv_thresh,n_iter_no_change=1, random_state = 0) #sklearn SGDClassifier model\n",
    "#sklearn_SGD_model.fit(X_1,Y_1)\n",
    "\n",
    "#test weights\n",
    "#print(own_log_reg_model.weights)\n",
    "#print(sklearn_log_reg_model.coef_)\n",
    "#print(sklearn_SGD_model.coef_)\n",
    "\n",
    "#test predictions\n",
    "#print(own_log_reg_model.predict(X_test_1)) #appears predictions match, weights are a bit off\n",
    "#print(sklearn_log_reg_model.predict(X_test_1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#no sklearn method to use batch stochastic gradient descent\n",
    "batch_size = 1\n",
    "conv_thresh = 0.0001\n",
    "#sk_log_reg_model = SKLogisticRegression(fit_intercept = False,tol=conv_thresh,penalty='l2',C=1)\n",
    "regularized = RegularizedLogisticRegression(batch_size)\n",
    "#learning rate is alpha? alpha is lambda if we do reg\n",
    "sk_log_reg_model = sklearn_SGDClassifier(loss = 'log_loss', fit_intercept = False, penalty = None,learning_rate = 'constant',eta0=0.03,tol=conv_thresh,n_iter_no_change=1, random_state = 0)\n",
    "# Smaller set of train and test data\n",
    "X_1 = np.random.rand(10, 2)\n",
    "X_1 = np.hstack((X_1,np.ones((len(X_1),1))))\n",
    "y_1 = np.random.randint(2,size=10)\n",
    "if y_1.sum() == len(y_1):\n",
    "    y_1[0:int(len(y_1)/2)] = 0\n",
    "elif y_1.sum() == 0:\n",
    "    y_1[0:int(len(y_1)/2)] = 1\n",
    "X_test_1 = np.random.rand(5, 2)\n",
    "X_test_1 = np.hstack((X_test_1,np.ones((len(X_test_1),1))))\n",
    "\n",
    "own_log_reg_model_1 = LogisticRegression(len(X_1[0,:]),2,batch_size,conv_thresh)\n",
    "regularized.train(X_1,y_1)\n",
    "own_log_reg_model_1.fit(X_1,y_1)\n",
    "sk_log_reg_model.fit(X_1,y_1)\n",
    "\n",
    "print('own log reg predictions:')\n",
    "print(own_log_reg_model_1.predict(X_test_1))\n",
    "print('sklearn log reg predictions:')\n",
    "print(sk_log_reg_model.predict(X_test_1))\n",
    "\n",
    "print(own_log_reg_model_1.weights)\n",
    "print(sk_log_reg_model.coef_)\n",
    "#print(regularized.predict(X_test_1))\n",
    "#assert(1-np.sum(np.abs(own_log_reg_model_1.predict(X_test_1)-sk_log_reg_model.predict(X_test_1)))/len(X_test_1) >= 0.8)\n",
    "#assert (own_log_reg_model_1.predict(X_test_1) == sk_log_reg_model.predict(X_test_1)).all()\n",
    "\n",
    "# Larger set of train and test data\n",
    "X_2 = np.random.rand(40, 5)\n",
    "X_2 = np.hstack((X_2,np.ones((len(X_2),1))))\n",
    "y_2 = np.random.randint(2, size = 40)\n",
    "if y_2.sum() >= len(y_2)*0.95:\n",
    "    y_2[0:len(y_2)/2] = 0\n",
    "elif y_1.sum() == 0:\n",
    "    y_2[0:len(y_2)/2] = 1\n",
    "X_test_2 = np.random.rand(10, 5)\n",
    "X_test_2 = np.hstack((X_test_2,np.ones((len(X_test_2),1))))\n",
    "\n",
    "own_log_reg_model_2 = LogisticRegression(len(X_2[0,:]),2,batch_size,conv_thresh)\n",
    "regularized.train(X_2,y_2)\n",
    "own_log_reg_model_2.fit(X_2,y_2)\n",
    "sk_log_reg_model.fit(X_2,y_2)\n",
    "\n",
    "print(own_log_reg_model_2.predict(X_test_2))\n",
    "print(sk_log_reg_model.predict(X_test_2))\n",
    "\n",
    "print(own_log_reg_model_2.weights)\n",
    "print(sk_log_reg_model.coef_)\n",
    "#print(regularized.predict(X_test_2))\n",
    "#assert(1-np.sum(np.abs(own_log_reg_model_2.predict(X_test_2)-sk_log_reg_model.predict(X_test_2)))/len(X_test_2) >= 0.8)\n",
    "#assert (own_log_reg_model_2.predict(X_test_2) == sk_log_reg_model.predict(X_test_2)).all()\n",
    "\n",
    "\n",
    "# Larger set of train and test data with wider range of values \n",
    "#actually don't do this bc we want to normalize the data!\n",
    "X_3 = np.random.uniform(low=-15, high=15, size=(30,5))\n",
    "X_3 = np.hstack((X_3,np.ones((len(X_3),1))))\n",
    "y_3 = np.random.randint(2, size = 30)\n",
    "X_test_3 = np.random.uniform(low=-15, high=15, size=(5,5))\n",
    "X_test_3 = np.hstack((X_test_3,np.ones((len(X_test_3),1))))\n",
    "\n",
    "own_log_reg_model_3 = LogisticRegression(len(X_3[0,:]),2,batch_size,conv_thresh)\n",
    "regularized.train(X_3,y_3)\n",
    "own_log_reg_model_3.fit(X_3,y_3)\n",
    "sk_log_reg_model.fit(X_3,y_3)\n",
    "\n",
    "print(own_log_reg_model_3.predict(X_test_3))\n",
    "print(sk_log_reg_model.predict(X_test_3))\n",
    "print(regularized.predict(X_test_3))\n",
    "#assert(1-np.sum(np.abs(own_log_reg_model_3.predict(X_test_3)-sk_log_reg_model.predict(X_test_3)))/len(X_test_3) >= 0.8)\n",
    "#assert (own_log_reg_model_3.predict(X_test_3) == sk_log_reg_model.predict(X_test_3)).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[337], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m own_log \u001b[38;5;241m=\u001b[39m LogisticRegression(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m,batch_size,conv_thresh)\n\u001b[1;32m      6\u001b[0m SK_log \u001b[38;5;241m=\u001b[39m sklearn_SGDClassifier(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, fit_intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m,eta0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m,tol\u001b[38;5;241m=\u001b[39mconv_thresh,n_iter_no_change\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mown_log\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m(train_1,y_train_1)\n\u001b[1;32m      8\u001b[0m SK_log\u001b[38;5;241m.\u001b[39mfit(train_1,y_train_1)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(own_log\u001b[38;5;241m.\u001b[39mweights)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "train_1 = np.array([[1,2,1],[3,-2,1],[3,3,1],[-4,1,1],[-1,-2,1],[-3,2,1]])\n",
    "y_train_1 = np.array([1,1,1,0,0,0])\n",
    "own_log = LogisticRegression(3,2,batch_size,conv_thresh)\n",
    "SK_log = sklearn_SGDClassifier(loss = 'log_loss', fit_intercept = False, penalty = None,learning_rate = 'constant',eta0=0.03,tol=conv_thresh,n_iter_no_change=1)\n",
    "own_log.train(train_1,y_train_1)\n",
    "SK_log.fit(train_1,y_train_1)\n",
    "\n",
    "print(own_log.weights)\n",
    "print(SK_log.coef_)\n",
    "\n",
    "test_1 = np.array([[1,2,1],[-4,1,1],[-10,-20,1],[200,-100,1]])\n",
    "print(own_log.predict(test_1))\n",
    "print(SK_log.predict(test_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests for Logistic Regression from HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931466805603205\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creates Test Model with 2 predictors, 2 classes, a Batch Size of 5 and a Threshold of 1e-2 (used 3 for predictors to include bias)\n",
    "test_model1 = LogisticRegression(3, 2, 5, 1e-2)\n",
    "\n",
    "# Creates Test Data\n",
    "x_bias = np.array([[0,4,1], [0,3,1], [5,0,1], [4,1,1], [0,5,1]])\n",
    "y = np.array([0,0,1,1,0])\n",
    "x_bias_test = np.array([[0,0,1], [-5,3,1], [9,0,1], [1,0,1], [6,-7,1]])\n",
    "y_test = np.array([0,0,1,0,1])\n",
    "\n",
    "# Creates Test Model with 2 predictors, 1 classes, a Batch Size of 1 and a Threshold of 1e-2\n",
    "test_model2 = LogisticRegression(3, 3, 1, 1e-2)\n",
    "\n",
    "# Creates Test Data\n",
    "x_bias2 = np.array([[0,0,1], [0,3,1], [4,0,1], [6,1,1], [0,1,1], [0,4,1]])\n",
    "y2 = np.array([0,1,2,2,0,1])\n",
    "x_bias_test2 = np.array([[0,0,1], [-5,3,1], [9,0,1], [1,0,1]])\n",
    "y_test2 = np.array([0,1,2,0])\n",
    "\n",
    "\n",
    "# Test Model Loss\n",
    "print(test_model1.loss(x_bias,y))\n",
    "assert test_model1.loss(x_bias, y) == pytest.approx(0.693, .001) # Checks if answer is within .001\n",
    "assert test_model2.loss(x_bias2, y2) == pytest.approx(1.099, .001) # Checks if answer is within .001\n",
    "\n",
    "# Test Train Model and Checks Model Weights\n",
    "assert test_model1.fit(x_bias, y) == 14\n",
    "assert test_model1.weights == pytest.approx(np.array([[-0.218, 0.231, 0.0174], [ 0.218, -0.231, -0.0174]]), 0.01) # Answer within .01\n",
    "\n",
    "assert test_model2.fit(x_bias, y) == 9\n",
    "assert test_model2.weights == pytest.approx(np.array([[-0.300,  0.560,  0.093], [ 0.523, -0.257,  0.032], [-0.226, -0.304, -0.123]]), .05)\n",
    "\n",
    "# Test Model Predict\n",
    "assert (test_model1.predict(x_bias_test) == np.array([0., 0., 1., 1., 1.])).all()\n",
    "assert (test_model2.predict(x_bias_test2) == np.array([0, 0, 1, 1])).all()\n",
    "\n",
    "# Test Model Accuracy\n",
    "assert test_model1.accuracy(x_bias_test, y_test) == .8\n",
    "assert test_model2.accuracy(x_bias_test2, y_test2) == .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for OnevsAll and AllPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One vs. All Logistic Regression multi-class regression classifier ###\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "class OneVsAll:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_classes: int,\n",
    "        batch_size: int,\n",
    "        conv_threshold: float,\n",
    "        classifier = 'own',\n",
    "    ) -> None:\n",
    "        self.n_classes = n_classes\n",
    "        self.classifier = classifier\n",
    "        if classifier == 'own':\n",
    "            self.models = [\n",
    "                LogisticRegression(n_features, 2, batch_size, conv_threshold) \n",
    "                for _ in range(n_classes)\n",
    "            ]\n",
    "        else:\n",
    "            self.models = [\n",
    "                SKLogisticRegression(fit_intercept = False) \n",
    "                for _ in range(n_classes)\n",
    "            ]\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray) -> None:\n",
    "        # Train a binary classifier for each class against all others\n",
    "        for class_label in range(self.n_classes):\n",
    "            binary_labels = (Y == class_label).astype(int)\n",
    "            if self.classifier == 'own':\n",
    "                self.models[class_label].train(X, binary_labels)\n",
    "            else:\n",
    "                self.models[class_label].fit(X, binary_labels)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Get the probabilities of each class for each data point\n",
    "        # print(\"X\", X.shape)\n",
    "\n",
    "        predictions = np.zeros(len(X))\n",
    "        if self.classifier == 'own':\n",
    "            for j in range(0,len(X)): #for each datapoint\n",
    "                probabilities = np.zeros(len(self.models))\n",
    "                for i in range(0,len(self.models)):\n",
    "                    #for each model i, it trains on if we relabel current class i as '1' and all other classes as '0'\n",
    "                    #so, the value from getSoftmaxProbability at index 1 would be probability of being in class 1 for that model, or our current class i\n",
    "                    prob_x_class_i = self.models[i].getSoftmaxProbability(X[j,:])[1] \n",
    "                    probabilities[i] = prob_x_class_i\n",
    "                predictions[j] = np.argmax(probabilities) #for all classes get the class with greatest probability\n",
    "        else:\n",
    "            for j in range(0,len(X)): #for each datapoint\n",
    "                probabilities = np.zeros(len(self.models))\n",
    "                for i in range(0,len(self.models)):\n",
    "                    #same as our own function except we construct our weights for both classes instead of just one class like from sklearn's coef_\n",
    "                    weights = np.zeros([2,len(self.models[i].coef_[0])])\n",
    "                    weights[0,:] = -self.models[i].coef_[0]\n",
    "                    weights[1,:] = self.models[i].coef_[0]\n",
    "                    prob_x_class_i = softmax(np.dot(weights,(X[j,:])))[1]\n",
    "                    probabilities[i] = prob_x_class_i\n",
    "                predictions[j] = np.argmax(probabilities) #for all classes get the class with greatest probability\n",
    "            \n",
    "        return predictions\n",
    "\n",
    "    def accuracy(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All Pairs Logistic Regression multi-class regression classifier ###\n",
    "\n",
    "class AllPairs:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_classes: int,\n",
    "        batch_size: int,\n",
    "        conv_threshold: float,\n",
    "        classifier: str = \"own\",\n",
    "    ):\n",
    "        self.n_classes = n_classes\n",
    "        self.pairs = list(it.combinations(range(n_classes), 2))\n",
    "        print(self.pairs)\n",
    "        self.classifier = classifier\n",
    "        if classifier == \"own\":\n",
    "            self.models = {\n",
    "                (i, j): LogisticRegression(\n",
    "                    n_features,\n",
    "                    2,\n",
    "                    batch_size,\n",
    "                    conv_threshold\n",
    "                )\n",
    "                for i, j in self.pairs\n",
    "            }\n",
    "        else:\n",
    "            self.models = {\n",
    "                (i, j): SKLogisticRegression(\n",
    "                    fit_intercept=False\n",
    "                )\n",
    "                for i, j in self.pairs\n",
    "            }\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray) -> None:\n",
    "        # Iterate over all pair combinations\n",
    "        #print(\"self pairs:\", self.pairs)\n",
    "        for i, j in self.pairs:\n",
    "            #print(\"ij\", i,j)\n",
    "            indices = (Y == i) | (Y == j)\n",
    "\n",
    "            # Get appropriate data\n",
    "            X_pair, Y_pair = X[indices], Y[indices]\n",
    "            Y_pair = (Y_pair == j).astype(int)\n",
    "\n",
    "            # Train on the pair\n",
    "            if self.classifier == 'own':\n",
    "                self.models[(i, j)].train(X_pair, Y_pair)\n",
    "            else:\n",
    "                self.models[(i, j)].fit(X_pair, Y_pair)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Count predictions for each class\n",
    "        votes = np.zeros((len(X), self.n_classes))\n",
    "        for (i, j), model in self.models.items():\n",
    "            predictions = np.array(model.predict(X))\n",
    "            # print(\"predictions shape:\", predictions.shape, predictions)\n",
    "            votes[:, j] += predictions\n",
    "            votes[:, i] += (1 - predictions)\n",
    "\n",
    "        # Return the class with the most predictions\n",
    "        return np.argmax(votes, axis=1)\n",
    "\n",
    "    def accuracy(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-All Accuracy: 0.264\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
      "All-Pairs Accuracy: 0.258\n"
     ]
    }
   ],
   "source": [
    "### Dummy test ###\n",
    "n_samples = 500\n",
    "n_features = 10\n",
    "n_classes = 5\n",
    "X = np.random.rand(n_samples, n_features)\n",
    "Y = np.random.randint(0, n_classes, n_samples)\n",
    "\n",
    "#One-vs-All\n",
    "ova = OneVsAll(n_features, n_classes, batch_size=32, conv_threshold=1e-4)\n",
    "ova.train(X, Y)\n",
    "print(f\"One-vs-All Accuracy: {ova.accuracy(X, Y)}\")\n",
    "\n",
    "# All-Pairs\n",
    "all_pairs = AllPairs(n_features, n_classes, batch_size=32, conv_threshold=1e-4)\n",
    "all_pairs.train(X, Y)\n",
    "print(f\"All-Pairs Accuracy: {all_pairs.accuracy(X, Y)}\")\n",
    "\n",
    "# TODO: Add unit tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn weights:\n",
      "(LogisticRegression(fit_intercept=False), LogisticRegression(fit_intercept=False), LogisticRegression(fit_intercept=False))\n",
      "Class 0 weights [[-0.17315305 -0.51387022  0.16819876  0.09515732]]\n",
      "\n",
      "Class 1 weights [[ 0.24780742 -0.31339288 -0.40551825  0.21331106]]\n",
      "\n",
      "Class 2 weights [[ 0.38846112  0.22371409 -0.54569867  0.1243528 ]]\n",
      "\n",
      "[(0, 1), (0, 2), (1, 2)]\n",
      "Our weights:\n",
      "Class (0, 1) weights [[ 0.17315305  0.51387022 -0.16819876 -0.09515732]]\n",
      "\n",
      "Class (0, 2) weights [[-0.24780742  0.31339288  0.40551825 -0.21331106]]\n",
      "\n",
      "Class (1, 2) weights [[-0.38846112 -0.22371409  0.54569867 -0.1243528 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run SKLearn's one verse all logistic regression using the example X_1 and X_2 datasets.\n",
    "# Get the weight matrix after training for each of the sub binary classifiers to\n",
    "# compare against the weights of our own implementation of one verse all\n",
    "# logistic regression. Also compare predictions and accuracy.\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Smaller test data\n",
    "X_1 = np.random.rand(6, 3)\n",
    "y_1 = np.array([0, 1, 2])\n",
    "X_test_1 = np.random.rand(3, 3)\n",
    "\n",
    "# Larger test data\n",
    "X_2 = np.random.rand(8, 4)\n",
    "y_2 = np.array([0, 1, 2, 0, 1, 2, 0, 2])\n",
    "X_test_2 = np.random.rand(4, 4)\n",
    "\n",
    "# Train sklearn all pairs logistic regression\n",
    "sk_model = OneVsOneClassifier(SKLogisticRegression(fit_intercept=False))\n",
    "sk_model.fit(X_2, y_2)\n",
    "\n",
    "# Print weights of each classes binary classification model\n",
    "print(\"SKLearn weights:\")\n",
    "print(sk_model.estimators_)\n",
    "for i, model in enumerate(sk_model.estimators_):\n",
    "    print(f\"Class {i} weights {model.coef_}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Train our own all pairs logistic regression\n",
    "all_pairs = AllPairs(4, 3, 1, 1e-4, \"sk\")\n",
    "all_pairs.train(X_2, y_2)\n",
    "\n",
    "# Print weights of each classes binary classification model\n",
    "print(\"Our weights:\")\n",
    "for i, model in all_pairs.models.items():\n",
    "    print(f\"Class {i} weights {model.coef_}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German Numerical Credit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (350, 70) (175, 70)\n",
      "num features: 70\n",
      "One-vs-All Accuracy: 0.7028571428571428\n",
      "One-vs-All Accuracy: 0.7028571428571428\n",
      "[(0, 1)]\n",
      "All-Pairs Accuracy: 0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_credit():\n",
    "    \"\"\"\n",
    "    Gets and preprocesses German Credit data\n",
    "    \"\"\"\n",
    "    #data = pd.read_csv('./data/german_numerical-binsensitive.csv') # Reads file - may change\n",
    "    data = pd.read_csv('./german_numerical-binsensitive.csv')\n",
    "    # MONTH categorizing\n",
    "    data['month'] = pd.cut(data['month'],3, labels=['month_1', 'month_2', 'month_3'], retbins=True)[0]\n",
    "    # month bins: [ 3.932     , 26.66666667, 49.33333333, 72.        ]\n",
    "    a = pd.get_dummies(data['month'])\n",
    "    data = pd.concat([data, a], axis = 1)\n",
    "    data = data.drop(['month'], axis=1)\n",
    "\n",
    "    # CREDIT categorizing\n",
    "    data['credit_amount'] = pd.cut(data['credit_amount'], 3, labels=['cred_amt_1', 'cred_amt_2', 'cred_amt_3'], retbins=True)[0]\n",
    "    # credit bins: [  231.826,  6308.   , 12366.   , 18424.   ]\n",
    "    a = pd.get_dummies(data['credit_amount'])\n",
    "    data = pd.concat([data, a], axis = 1)\n",
    "    data = data.drop(['credit_amount'], axis=1)\n",
    "\n",
    "    for header in ['investment_as_income_percentage', 'residence_since', 'number_of_credits']:\n",
    "        a = pd.get_dummies(data[header], prefix=header)\n",
    "        data = pd.concat([data, a], axis = 1)\n",
    "        data = data.drop([header], axis=1)\n",
    "\n",
    "    # change from 1-2 classes to 0-1 classes\n",
    "    data['people_liable_for'] = data['people_liable_for'] -1\n",
    "    data['credit'] = -1*(data['credit']) + 2 # original encoding 1: good, 2: bad. we switch to 1: good, 0: bad\n",
    "\n",
    "    # balance dataset\n",
    "    data = data.reindex(np.random.permutation(data.index)) # shuffle\n",
    "    pos = data.loc[data['credit'] == 1]\n",
    "    neg = data.loc[data['credit'] == 0][:350]\n",
    "    combined = pd.concat([pos, neg])\n",
    "\n",
    "    y = data.iloc[:, data.columns == 'credit'].to_numpy()\n",
    "    x = data.drop(['credit', 'sex', 'age', 'sex-age'], axis=1).to_numpy()\n",
    "\n",
    "    # split into train and validation\n",
    "    X_train, X_val, y_train, y_val = x[:350, :], x[351:526, :], y[:350, :].reshape([350,]), y[351:526, :].reshape([175,])\n",
    "\n",
    "    # keep info about sex and age of validation rows for fairness portion\n",
    "    x_sex = data.iloc[:, data.columns == 'sex'].to_numpy()[351:526].reshape([175,])\n",
    "    x_age = data.iloc[:, data.columns == 'age'].to_numpy()[351:526].reshape([175,])\n",
    "    x_sex_age = data.iloc[:, data.columns == 'sex-age'].to_numpy()[351:526].reshape([175,])\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, x_sex, x_age, x_sex_age\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test, x_sex, x_age, x_sex_age = get_credit()\n",
    "n_samples = len(X_train)\n",
    "n_features = len(X_train[0])+1\n",
    "n_classes = 2\n",
    "\n",
    "# process data\n",
    "X_train[X_train == False] = 0.0\n",
    "X_train[X_train == True] = 1.0\n",
    "X_test[X_test == False] = 0.0\n",
    "X_test[X_test == True] = 1.0\n",
    "\n",
    "train_bias = np.ones((n_samples, 1))\n",
    "X_train = np.hstack((X_train, train_bias))\n",
    "\n",
    "test_bias = np.ones((len(X_test), 1))\n",
    "X_test = np.hstack((X_test, test_bias))\n",
    "\n",
    "print(\"x shape:\", X_train.shape, X_test.shape)\n",
    "print(\"num features:\", n_features)\n",
    "\n",
    "batch_size = 50\n",
    "conv_threshold = 1e-5\n",
    "\n",
    "# One-vs-All\n",
    "ova = OneVsAll(n_features, n_classes, batch_size=batch_size, conv_threshold=conv_threshold)\n",
    "ova.train(X_train, y_train)\n",
    "print(f\"One-vs-All Accuracy: {ova.accuracy(X_test, y_test)}\")\n",
    "\n",
    "ova = OneVsAll(n_features, n_classes, batch_size=batch_size, conv_threshold=conv_threshold, classifier = 'sk')\n",
    "ova.train(X_train, y_train)\n",
    "print(f\"One-vs-All Accuracy: {ova.accuracy(X_test, y_test)}\")\n",
    "\n",
    "# All-Pairs\n",
    "\n",
    "all_pairs = AllPairs(n_features, n_classes, batch_size=batch_size, conv_threshold=conv_threshold)\n",
    "all_pairs.train(X_train, y_train)\n",
    "print(f\"All-Pairs Accuracy: {all_pairs.accuracy(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkLearn Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number samples:  150 Number Feats:  5\n",
      "One-vs-All Accuracy: 0.9\n",
      "[0. 2. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 2. 0. 0. 1. 1. 1.\n",
      " 1. 1. 2. 1. 2. 0.]\n",
      "[(0, 1), (0, 2), (1, 2)]\n",
      "All-Pairs Accuracy: 0.9333333333333333\n",
      "[0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 2 1 2 0 0 2 1 2 1 2 2 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "\n",
    "#normalize the data to value between 0 and 1 for each attribute\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "\n",
    "\n",
    "n_samples = len(X)\n",
    "n_features = len(X[0])+1 #for bias\n",
    "n_classes = 3\n",
    "batch_size = 1\n",
    "conv_threshold = 1e-4\n",
    "\n",
    "print(\"Number samples: \", n_samples, \"Number Feats: \", n_features)\n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(1)\n",
    "p = np.random.permutation(n_samples)\n",
    "X_ = X[p]\n",
    "Y_ = Y[p]\n",
    "\n",
    "# add bias to shuffled data\n",
    "bias = np.ones((n_samples,1))\n",
    "X_ = np.hstack((X_, bias))\n",
    "\n",
    "# split data 80/20\n",
    "train_size = int(.8*n_samples)\n",
    "X_train = X_[:train_size,:]\n",
    "y_train = Y_[:train_size]\n",
    "\n",
    "X_test = X_[train_size:, :]\n",
    "y_test = Y_[train_size:]\n",
    "\n",
    "### our own model accuracy ###\n",
    "# One-vs-All\n",
    "ova = OneVsAll(n_features, n_classes, batch_size=batch_size, conv_threshold=conv_threshold)\n",
    "ova.train(X_train, y_train)\n",
    "print(f\"One-vs-All Accuracy: {ova.accuracy(X_test, y_test)}\")\n",
    "print(ova.predict(X_test))\n",
    "\n",
    "# All-Pairs\n",
    "\n",
    "all_pairs = AllPairs(n_features, n_classes, batch_size=batch_size, conv_threshold=conv_threshold)\n",
    "all_pairs.train(X_train, y_train)\n",
    "print(f\"All-Pairs Accuracy: {all_pairs.accuracy(X_test, y_test)}\")\n",
    "print(all_pairs.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn model on Iris Dataset (can change between LogisticRegression and SGDClassifier as binary algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk model one-vs-all accuracy: 0.9\n",
      "[0 2 0 1 0 1 1 0 0 1 0 1 2 0 1 1 2 1 2 0 0 2 1 2 1 2 2 2 2 0]\n",
      "sk model all-pairs accuracy: 0.9333333333333333\n",
      "[0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 2 1 2 0 0 2 1 2 1 2 2 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "### using sklearn model get accuracy ### there's some randomness with the sklearn function because of SGD!!\n",
    "#from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "#sk_model_allpairs = OneVsOneClassifier(SKLogisticRegression(fit_intercept=False))\n",
    "#sk_model_ovr = OneVsRestClassifier(SKLogisticRegression(fit_intercept=False))\n",
    "sk_model_allpairs = OneVsOneClassifier(sklearn_SGDClassifier(loss = 'log_loss', fit_intercept = False, penalty = None,learning_rate = 'constant',eta0=0.03,tol=conv_threshold,n_iter_no_change=1))\n",
    "sk_model_ovr = OneVsRestClassifier(sklearn_SGDClassifier(loss = 'log_loss', fit_intercept = False, penalty = None,learning_rate = 'constant',eta0=0.03,tol=conv_threshold,n_iter_no_change=1))\n",
    "\n",
    "sk_model_allpairs.fit(X_train, y_train)\n",
    "sk_model_ovr.fit(X_train,y_train)\n",
    "\n",
    "print(f\"sk model one-vs-all accuracy: {sk_model_ovr.score(X_test,y_test)}\")\n",
    "print(sk_model_ovr.predict(X_test))\n",
    "print(f\"sk model all-pairs accuracy: {sk_model_allpairs.score(X_test,y_test)}\")\n",
    "print(sk_model_allpairs.predict(X_test))\n",
    "\n",
    "\n",
    "###for raw data accuracy works on seed 30, 54, conv_threshold = 1e-4\n",
    "###for normalized data accuracy works on seed 107, 170,174, conv_threshold = 1e-5\n",
    "#comparing own models with own logistic regression against classifiers with SGDClassifier as their baseline log reg\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we got 0.766666 accuracy and 0.9333333 accuracy for ova and all pairs for our implementation\n",
    "#0.7, 0.9 accuracy for sklearn implementation for the below datasets! if set seed = 0\n",
    "#get better results for our model too if seed = 6 (all conv_threshold = 1e-4, batch_size=1)\n",
    "\n",
    "#for seed = 30 we get same accuracy for both models! for raw data\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(sk_model_ovr.estimators_[0].coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
